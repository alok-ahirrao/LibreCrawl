Initializing Crawler with User Config...

Setting up crawl for: https://webfx.com
Base Domain: webfx.com
Base URL: https://webfx.com

--- Testing URLs ---

Testing: https://webfx.com/
  is_internal: True
  is_subdomain_logic: False
  extension: None (Allowed)
  Checking robots.txt for https://webfx.com/...
  allowed_robots: True
  Robots Cache Hit: https://webfx.com/robots.txt
  User Agent used: LibreCrawl/1.0 (Dental Growth OS)
  Direct rp.can_fetch('LibreCrawl/1.0 (Dental Growth OS)', 'https://webfx.com/'): True
  Direct rp.can_fetch('*', 'https://webfx.com/'): True
  --- Robots.txt Content Start ---
User-agent: ia_archiver
Disallow: /

User-agent: *
Disallow: /referral/
Disallow: /old/
Disallow: /PDF/
Disallow: /PPT/
Disallow: /mobile/
Disallow: /jobs/
Disallow: /tools/read-able/check.php*
Disallow: /lp/
Disallow: /new-templates/
Disallow: /fx-testimonials/
Disallow: /clientpoint/
Disallow: /wp-admin/
Disallow: /testimonial/
Disallow: /case-studies/
Disallow: /stats/
Disallow: /style/
Disallow: /*?action=fx_tracking_data
Disallow: /wp-list-pages-by-q-schema.php
Disallo
  --- Robots.txt Content End ---
